Workbook for demultiplexing assignment
working on Talapas
data directory: /projects/bgmp/shared/2017_sequencing
personal working dir: /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing

7-29-20

peaked at input fastQ files to see which was the index vs read based on seq length
Filename	Contents	Readcount
1294_S1_L008_R1_001.fastq.gz	Read1	
1294_S1_L008_R2_001.fastq.gz	Index1
1294_S1_L008_R3_001.fastq.gz	Index2
1294_S1_L008_R4_001.fastq.gz	Read2
Have to calculate # of reads for input into mean calculator
got wc -l for read files, took forever 
1452986940 / 4 = 363,246,735

drafted python script to calculate mean qscores at each position
adapted from ps9

7-30-20

Made a slurm script
when working with gzip.open, the normal 'r' mode returns binary. have to use 'tr' to get actual values
had to specify 'python' before the filename in my slurm script
I realized that hardcoding the qscores list length isn't good for the index reads, made it dynamically calculate
list length based on length of 1st qscore line encountered. I also made it dynamically calculate total number of records
for more broad applicability

finished read1. Runtime stats:
Command being timed: "python /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/part1.py -i /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R1_001.fastq.gz -o read1"
User time (seconds): 11955.64
System time (seconds): 3.85
Percent of CPU this job got: 98%
Elapsed (wall clock) time (h:mm:ss or m:ss): 3:22:22
Maximum resident set size (kbytes): 59876

indeces stats
Command being timed: "python /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/part1.py -i /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R2_001.fastq.gz -o index1"
        User time (seconds): 955.73
        System time (seconds): 0.69
        Percent of CPU this job got: 99%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 16:02.72
        Maximum resident set size (kbytes): 58776

        
counted all reads with 'N' in the indeces
zcat /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R2_001.fastq.gz /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R3_001.fastq.gz | awk 'NR % 4 == 2' | grep 'N' -c

8/3/20

unix command for test files
python demultiplexing.py -f /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-input_FASTQ/ -x /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-input_FASTQ/indexes.txt -o /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-output_FASTQ/

Unit tests:
passed in actual index file. 24 indices in file. 
Expecting 24 indices read (ignoring top column)
got 24 indices in list

making permutations
Expecting 576 permutations of those indices
ran test, the dictionary of permutations had 576 elements :)

open input files returns dictionary with 4 items, one for each input file

8/4/20

output file opener should open 52 files, 2 for each index, 2 for mismatched, and 2 for unknown reads.
52 files are in the test output folder

passed in 4 reads with Ns in indices, evaluate_reads correctly identified them as 'unknown'
a read with really poor qscores was identified as 'unknown'

8/5/20
made new argparse to accept directions to each input file, not just the parent directory
added runtime option for output file format
new command for testing
python demultiplexing.py -r /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-input_FASTQ/test_R1.fastq.gz -R /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-input_FASTQ/test_R4.fastq.gz -i /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-input_FASTQ/test_R2.fastq.gz -I /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-input_FASTQ/test_R3.fastq.gz -x /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-input_FASTQ/indexes.txt -o /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/TEST-output_FASTQ/ -f test_out
need to check that program is getting reverse compliment of reads
input :
        index 1 = ACTTCGAC
        qscore  = AAA<FJJJ
        index 2 = GTCGAAGT                                                                            +
        qscore 2= AAAAAJJF
expected output:
        evaluate_reads returns 'paired'
        since indices aren't in the index file, they should get put in the undetermined files
performing as expected

full  command for actual data
python ./demultiplexing.py -r /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R1_001.fastq.gz -i /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R2_001.fastq.gz -I /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R3_001.fastq.gz -R /projects/bgmp/shared/2017_sequencing/1294_S1_L008_R4_001.fastq.gz -x /projects/bgmp/shared/2017_sequencing/indexes.txt -o /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/Assignment-the-third/output/ -f 1294_S1_L008 -q 26

full slurm script
#!/bin/bash
#SBATCH --account=bgmp
#SBATCH --partition=bgmp
#SBATCH --job-name=DG_demult_part3
#SBATCH --output=demult_part3.out
#SBATCH --error=demult_part3.err
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --time=24:00:00
#SBATCH --cpus-per-task=1

conda activate bgmp_py37

/usr/bin/time -v python /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiplexing-derrik-gratz/Assignment-the-third/demultiplexing.py -r /projects/bgmp/shared/2017_sequencin$
/usr/bin/time -v gzip /projects/bgmp/dgratz/bioinfo/Bi622/demultiplexing/demultiple$


trying to gzip output files within slurm script, we'll see how that goes

submitted slurm script
Submitted batch job 12663470

8/6/20

full run stats from script
Total records for index pair category:
undetermined    28433118        %7.827494443962449
misindexed      12985206        %3.574761931445853
paired  321828411       %88.5977436245917

Total number of records 363246735

runtime stats
User time (seconds): 10686.03
        System time (seconds): 68.68
        Percent of CPU this job got: 99%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 3:00:40
        Maximum resident set size (kbytes): 240208

running again with q cutoff of 30 to compare results
job ID 12665623

I noticed there were way too many lines in the output stats
changed it so only paired and index hopped counts are reported, not unknown counts

new job id 12665627

Still getting high % misindexed. troubleshooting
I realized that I was putting all complete, mis-matched indices in the 'hopped' category. I had assumed that if it passed qscore check and 
had no unknown basepairs that it was either paired or hopped at that point. I didn't consider that I should check that the two
indices are actually present in the input indices file. reruning

job id 12669587

stats output
Total records for index pair category:
undetermined    57748853        %15.897968910856141
misindexed      517612  %0.1424959814160477
paired  304980270       %83.95953510772782

Total number of records 363246735

runtime stats
User time (seconds): 6475.23
        System time (seconds): 70.85
        Percent of CPU this job got: 98%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 1:50:13
        Maximum resident set size (kbytes): 126420

zipping stats
User time (seconds): 19254.06
        System time (seconds): 81.64
        Percent of CPU this job got: 99%
        Elapsed (wall clock) time (h:mm:ss or m:ss): 5:23:31
        Maximum resident set size (kbytes): 900